{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!export CUDA_VISIBLE_DEVICES=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n",
      "sys.version_info(major=3, minor=7, micro=6, releaselevel='final', serial=0)\n",
      "Num GPUs Available:  0\n",
      "data loaded successfully\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "#import tensorflow_addons as tfa\n",
    "\n",
    "print(tf.__version__)\n",
    "print(sys.version_info)\n",
    "\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "#%%\n",
    "\n",
    "folder = os.path.join('..','short_data_4_model','20')\n",
    "\n",
    "\n",
    "data_train = np.load(os.path.join(folder, 'train_data.npz'),'r')\n",
    "data_train = data_train['arr_0']\n",
    "\n",
    "data_test = np.load(os.path.join(folder, 'test_data.npz'),'r')\n",
    "data_test_1 = data_test['arr_0']\n",
    "\n",
    "data_valid = np.load(os.path.join(folder, 'valid_data.npz'),'r')\n",
    "data_valid = data_valid['arr_0']\n",
    "\n",
    "\n",
    "'''\n",
    "data_valid = np.load(os.path.join(folder, 'valid_data.npz'),'r')\n",
    "data_valid = data_valid['arr_0']\n",
    "\n",
    "data_test = np.load(os.path.join(folder, 'test_data.npz'),'r')\n",
    "'''\n",
    "\n",
    "print('data loaded successfully')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52449, 20, 3)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(data_valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54830, 20, 3)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(data_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EPOCHS = 200\n",
    "#BATCH_SIZE =17\n",
    "BATCH_SIZE = 60\n",
    "seq_len =20\n",
    "units = 150\n",
    "# no use\n",
    "embedding_dim = 256\n",
    "\n",
    "num_examples = len(data_train)\n",
    "steps_per_epoch = num_examples//BATCH_SIZE\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices(data_train).shuffle(num_examples)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer encoder is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "embedding output shape: (batch size, sequence length, units) (60, 20, 3)\n",
      "Encoder output shape: (batch size, sequence length, units) (60, 20, 150)\n",
      "Encoder Hidden state shape: (batch size, units) (60, 150)\n"
     ]
    }
   ],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, embedding_dim, encoding_units, batch_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.encoding_units = encoding_units\n",
    "        self.inputs = tf.keras.layers.Input((seq_len, 3))\n",
    "\n",
    "        self.gru = keras.layers.GRU(self.encoding_units,\n",
    "                                    return_sequences=True,\n",
    "                                    return_state=True,\n",
    "                                    recurrent_initializer='glorot_uniform')\n",
    "\n",
    "    def call(self, x, hidden):\n",
    "        inputs = x\n",
    "\n",
    "        output, h = self.gru(inputs, initial_state = hidden)\n",
    "        return inputs,output, h\n",
    "\n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_size,self.encoding_units))\n",
    "    \n",
    "\n",
    "example_input_batch = np.zeros((BATCH_SIZE,20,3))\n",
    "# sample input\n",
    "encoder = Encoder( embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "embeded, sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
    "\n",
    "\n",
    "print('embedding output shape: (batch size, sequence length, units) {}'.format(embeded.shape))\n",
    "print('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
    "print('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention result shape: (batch size, units) (60, 150)\n",
      "Attention weights shape: (batch_size, sequence_length, 1) (60, 20, 1)\n"
     ]
    }
   ],
   "source": [
    "class BahdanauAttention(tf.keras.Model):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, query, values):\n",
    "        # query: encoder hidden state  (batch size, units) \n",
    "        # values: encoder output  (batch size, sequence length, units)\n",
    "        # hidden shape == (batch_size, hidden size)\n",
    "        # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "        # we are doing this to perform addition to calculate the score\n",
    "        hidden_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "        # score shape == (batch_size, max_length, 1)\n",
    "        # we get 1 at the last axis because we are applying score to self.V\n",
    "        # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
    "        score = self.V(tf.nn.tanh(self.W1(values) + self.W2(hidden_with_time_axis)))\n",
    "\n",
    "        # attention_weights shape == (batch_size, max_length, 1)\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "        # context_vector shape after sum == (batch_size, hidden_size)\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights\n",
    "    \n",
    "attention_layer = BahdanauAttention(units)\n",
    "\n",
    "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
    "\n",
    "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
    "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder output shape: (batch_size, vocab size) (60, 1, 3)\n"
     ]
    }
   ],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, decoding_units, batch_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.decoding_units = decoding_units\n",
    "        #self.embedding = keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = keras.layers.GRU(self.decoding_units,\n",
    "                                    return_sequences=True,\n",
    "                                    return_state=True,\n",
    "                                    recurrent_initializer='glorot_uniform')\n",
    "        self.fc = keras.layers.Dense(vocab_size)\n",
    "        \n",
    "        self.fcn_4 = keras.layers.Dense(64, activation = 'relu')\n",
    "        self.fcn_5 = keras.layers.Dense(32, activation='relu')\n",
    "\n",
    "        # used for attention\n",
    "        self.attention = BahdanauAttention(self.decoding_units)\n",
    "\n",
    "    def call(self,  hidden, encoding_output,embedder):\n",
    "        # enc_output shape == (batch_size, max_length, hidden_size)\n",
    "        context_vector, attention_weights = self.attention(hidden, encoding_output)\n",
    "\n",
    "        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "        #x = self.embedding(x)\n",
    "\n",
    "        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), embedder], axis=-1)\n",
    "\n",
    "        # passing the concatenated vector to the GRU\n",
    "        output, state = self.gru(x)\n",
    "        x = self.fc(output)\n",
    "\n",
    "\n",
    "        return x, state, attention_weights\n",
    "    \n",
    "\n",
    "vocab_size=3\n",
    "decoder = Decoder( vocab_size ,embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "embeded = tf.expand_dims(embeded[:,0,:],1)\n",
    "sample_decoder_output, _, _ = decoder(sample_hidden, sample_output, embeded)\n",
    "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = str(seq_len)+'full_seq2seq_attention_'+str(units)+'_'+str(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20full_seq2seq_attention_150_60'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.MeanSquaredError( reduction=tf.keras.losses.Reduction.NONE)\n",
    "\n",
    "@tf.function\n",
    "def loss_function(real, pred):\n",
    "    \n",
    "    #mask = tf.math.logical_not(tf.math.equal(real, [0,0,0]))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    #mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    #loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)\n",
    "\n",
    "\n",
    "\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.mkdir(checkpoint_dir)\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_step(inp, targ, encoding_hidden):\n",
    "    loss = 0\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        embeded_or, encoding_output, encoding_hidden = encoder(inp, encoding_hidden)\n",
    "\n",
    "        decoding_hidden = encoding_hidden\n",
    "        \n",
    "        embeded = tf.expand_dims(embeded_or[:,0,:],1)\n",
    "\n",
    "        #decoding_input = tf.expand_dims(inp[:,0,:], 1)\n",
    "\n",
    "        # Teacher forcing - feeding the target as the next input\n",
    "        for t in range(1, targ.shape[1]):\n",
    "            # passing enc_output to the decoder\n",
    "            predictions, decoding_hidden, _ = decoder( decoding_hidden, encoding_output, embeded)\n",
    "            tmp = np.expand_dims(targ[:,t,:],1)\n",
    "            loss += loss_function(tmp, predictions)\n",
    "\n",
    "            # using teacher forcing\n",
    "            embeded = tf.expand_dims(embeded_or[:,t,:],1)\n",
    "\n",
    "    batch_loss = (loss / int(targ.shape[1]))\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "    return batch_loss\n",
    "\n",
    "\n",
    "\n",
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    encoding_hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch, inp in enumerate(dataset.take(steps_per_epoch)):\n",
    "        batch_loss = train_step(inp, inp, encoding_hidden)\n",
    "        total_loss += batch_loss\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1, batch, batch_loss.numpy()))\n",
    "\n",
    "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "            \n",
    "    # saving (checkpoint) the model every 2 epochs\n",
    "    \n",
    "\n",
    "    print('Epoch {} Loss {:.4f}'.format(epoch + 1, total_loss / steps_per_epoch))\n",
    "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20full_seq2seq_attention_150_60'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: 8.2102237722245\n",
      "2: 8.157753466058477\n",
      "3: 8.1723406291088\n",
      "4: 8.00622690636285\n",
      "5: 8.006250327179684\n",
      "6: 7.983460078840455\n",
      "7: 7.8958071608098\n",
      "8: 8.010087453632625\n",
      "9: 7.795289443465857\n",
      "10: 8.002079713659322\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    f = open(os.path.join(checkpoint_dir,'checkpoint'), 'w')\n",
    "    f.write('model_checkpoint_path: \"ckpt-'+str(i+1)+'\"\\n')\n",
    "    f.write('all_model_checkpoint_paths: \"ckpt-'+str(i+1)+'\"\\n')\n",
    "    f.close()\n",
    "    checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "    \n",
    "    result, _ = evaluate(data_valid)\n",
    "    mse_idv =loss_function(data_valid, result)\n",
    "    print(str(i+1)+': '+str(mse_idv.numpy()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x22a529ea548>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input (num_fiber ,550, 3)\n",
    "def evaluate(inputs):\n",
    "    result = np.zeros((np.shape(inputs)))\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "  \n",
    "    inference_batch_size = inputs.shape[0]\n",
    "    hidden = [tf.zeros((inference_batch_size, units))]\n",
    "    embeded_or,encoding_out, encoding_hidden = encoder(inputs, hidden)\n",
    "\n",
    "    decoding_hidden = encoding_hidden\n",
    "\n",
    "\n",
    "\n",
    "    for t in range(seq_len):\n",
    "        embeded = tf.expand_dims(embeded_or[:,t,:],1)\n",
    "        predictions, decoding_hidden, attention_weights = decoder(decoding_hidden, encoding_out, embeded)\n",
    "\n",
    "    \n",
    "        result[:,t,:] = tf.squeeze(predictions)\n",
    "\n",
    "        # the predicted ID is fed back into the model\n",
    "        decoding_input = predictions\n",
    "\n",
    "    return result, inputs\n",
    "\n",
    "\n",
    "checkpoint_dir = str(seq_len)+'full_seq2seq_attention_'+str(units)+'_'+str(BATCH_SIZE)\n",
    "optimizer = keras.optimizers.Adam()\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)\n",
    "\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "print(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'data_4_model_new'\n",
    "test_list = np.load(os.path.join('..',folder, 'test_list.npy'),'r')\n",
    "train_list = np.load(os.path.join('..',folder, 'train_list.npy'),'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken 2.8093748092651367 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "subj = test_list[10]\n",
    "name = os.path.splitext(subj)[0]\n",
    "test_data = np.load(os.path.join('..','subsample-data',str(seq_len), subj),'r')\n",
    "test_data = test_data['arr_0']\n",
    "start = time.time()\n",
    "result, _ = evaluate(test_data)\n",
    "print('Time taken {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2135, 20, 3)\n",
      "(2135, 20, 3)\n",
      "tf.Tensor(8.397514609490681, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(test_data))\n",
    "print(np.shape(result))\n",
    "print(loss_function(test_data,result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "def cal_mse(data_raw,data_pred):\n",
    "    mse = np.zeros(np.shape(data_raw)[0])\n",
    "    for i in range(np.shape(data_raw)[0]):\n",
    "        result = mean_squared_error(data_raw[i], data_pred[i])\n",
    "        mse[i] = result\n",
    "    return mse  \n",
    "mse_idv = cal_mse(test_data, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, '# streamlines')"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(1)\n",
    "ax.hist(mse_idv, bins=200, histtype='step')\n",
    "ax.set_xlabel('MSE')\n",
    "ax.set_ylabel('# streamlines') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dic = os.path.join('..','toolkit')\n",
    "sys.path.append(r'..\\\\toolkit')\n",
    "\n",
    "from visualize_score import  visualize_streamline, visualize_streamline_removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.346338652713932\n"
     ]
    }
   ],
   "source": [
    "thre = np.percentile(mse_idv,91)\n",
    "print(thre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = 1*(mse_idv<thre)\n",
    "visualize_streamline(test_data,pred,control_par=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x22a53637d88>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open(os.path.join(checkpoint_dir,'checkpoint'), 'w')\n",
    "f.write('model_checkpoint_path: \"ckpt-'+str(6)+'\"\\n')\n",
    "f.write('all_model_checkpoint_paths: \"ckpt-'+str(6)+'\"\\n')\n",
    "f.close()\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 of 29 finished\n",
      "2 of 29 finished\n",
      "3 of 29 finished\n",
      "4 of 29 finished\n",
      "5 of 29 finished\n",
      "6 of 29 finished\n",
      "7 of 29 finished\n",
      "8 of 29 finished\n",
      "9 of 29 finished\n",
      "10 of 29 finished\n",
      "11 of 29 finished\n",
      "12 of 29 finished\n",
      "13 of 29 finished\n",
      "14 of 29 finished\n",
      "15 of 29 finished\n",
      "16 of 29 finished\n",
      "17 of 29 finished\n",
      "18 of 29 finished\n",
      "19 of 29 finished\n",
      "20 of 29 finished\n",
      "21 of 29 finished\n",
      "22 of 29 finished\n",
      "23 of 29 finished\n",
      "24 of 29 finished\n",
      "25 of 29 finished\n",
      "26 of 29 finished\n",
      "27 of 29 finished\n",
      "28 of 29 finished\n",
      "29 of 29 finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "def cal_mse(data_raw,data_pred):\n",
    "    mse = np.zeros(np.shape(data_raw)[0])\n",
    "    for i in range(np.shape(data_raw)[0]):\n",
    "        result = mean_squared_error(data_raw[i], data_pred[i])\n",
    "        mse[i] = result\n",
    "    return mse  \n",
    "\n",
    "\n",
    "def cal_mse_all(test_list):\n",
    "    result=[]\n",
    "    for i in range(len(test_list)):\n",
    "\n",
    "        name = test_list[i]\n",
    "        test_data = np.load(os.path.join('..','subsample-data',str(seq_len), name),'r')\n",
    "        test_data = test_data['arr_0']\n",
    "        denoise, _ = evaluate(test_data)\n",
    "        #denoise = denoise.numpy()\n",
    "        mse_idv = cal_mse(test_data, denoise)\n",
    "        print(str(i+1)+' of '+str(len(test_list))+' finished')\n",
    "        result.append(mse_idv)\n",
    "    return result\n",
    "\n",
    "def mse_cal(testlist,filename):\n",
    "    result = cal_mse_all(test_list)\n",
    "    path_save = os.path.join('result', filename)\n",
    "    np.save(path_save, result)\n",
    "    return result\n",
    "\n",
    "\n",
    "result = mse_cal(test_list,str(seq_len)+'full_seq2seq_attention_'+ str(units)+'_'+str(BATCH_SIZE) +'oup_mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29,)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse =[]\n",
    "\n",
    "for i, subj in enumerate(test_list):\n",
    "\n",
    "    mse_tmp = np.array(result[i])\n",
    "    mse = np.concatenate((mse,mse_tmp), axis=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, '# streamlines')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(1)\n",
    "ax.hist(mse, bins=200,range=(0,25), histtype='step')\n",
    "ax.set_xlabel('MSE')\n",
    "ax.set_ylabel('# streamlines')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, '# streamlines')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(1)\n",
    "ax.hist(result[10], range=(0,25),bins=200, histtype='step')\n",
    "ax.set_xlabel('MSE')\n",
    "ax.set_ylabel('# streamlines')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
