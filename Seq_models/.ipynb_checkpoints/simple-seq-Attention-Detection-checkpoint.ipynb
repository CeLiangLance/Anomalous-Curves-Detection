{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n",
      "Num GPUs Available:  0\n",
      "data loaded successfully\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "#import tensorflow_addons as tfa\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "#%%\n",
    "\n",
    "folder = os.path.join('..','..','short_data_4_model','50')\n",
    "\n",
    "\n",
    "data_train = np.load(os.path.join(folder, 'train_data.npz'),'r')\n",
    "data_train = data_train['arr_0']\n",
    "\n",
    "\n",
    "\n",
    "data_valid = np.load(os.path.join(folder, 'valid_data.npz'),'r')\n",
    "data_valid = data_valid['arr_0']\n",
    "'''\n",
    "data_valid = np.load(os.path.join(folder, 'valid_data.npz'),'r')\n",
    "data_valid = data_valid['arr_0']\n",
    "\n",
    "data_test = np.load(os.path.join(folder, 'test_data.npz'),'r')\n",
    "data_test = data_test['arr_0']\n",
    "'''\n",
    "print('data loaded successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(183666, 50, 3)\n",
      "(52449, 50, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ndata_train = data_train[0:80000] \\ndata_valid = data_valid[0:30000]\\nprint(np.shape(data_train))\\nprint(np.shape(data_valid))\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.shape(data_train))\n",
    "print(np.shape(data_valid))\n",
    "'''\n",
    "data_train = data_train[0:80000] \n",
    "data_valid = data_valid[0:30000]\n",
    "print(np.shape(data_train))\n",
    "print(np.shape(data_valid))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 60\n",
    "seq_len =50\n",
    "units = 200\n",
    "# no use\n",
    "embedding_dim = 256\n",
    "\n",
    "num_examples = len(data_train)\n",
    "steps_per_epoch = num_examples//BATCH_SIZE\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices(data_train).shuffle(num_examples)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer encoder is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "embedding output shape: (batch size, sequence length, units) (60, 20, 3)\n",
      "Encoder output shape: (batch size, sequence length, units) (60, 20, 200)\n",
      "Encoder Hidden state shape: (batch size, units) (60, 200)\n"
     ]
    }
   ],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, embedding_dim, encoding_units, batch_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.encoding_units = encoding_units\n",
    "        self.inputs = tf.keras.layers.Input((seq_len, 3))\n",
    "\n",
    "        self.gru = keras.layers.GRU(self.encoding_units,\n",
    "                                    return_sequences=True,\n",
    "                                    return_state=True,\n",
    "                                    recurrent_initializer='glorot_uniform')\n",
    "\n",
    "    def call(self, x, hidden):\n",
    "        inputs = x\n",
    "\n",
    "        output, h = self.gru(inputs, initial_state = hidden)\n",
    "        return inputs,output, h\n",
    "\n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_size,self.encoding_units))\n",
    "    \n",
    "\n",
    "example_input_batch = np.zeros((BATCH_SIZE,20,3))\n",
    "# sample input\n",
    "encoder = Encoder( embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "embeded, sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
    "\n",
    "\n",
    "print('embedding output shape: (batch size, sequence length, units) {}'.format(embeded.shape))\n",
    "print('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
    "print('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention result shape: (batch size, units) (60, 200)\n",
      "Attention weights shape: (batch_size, sequence_length, 1) (60, 20, 1)\n"
     ]
    }
   ],
   "source": [
    "class BahdanauAttention(tf.keras.Model):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, query, values):\n",
    "        # query: encoder hidden state  (batch size, units) \n",
    "        # values: encoder output  (batch size, sequence length, units)\n",
    "        # hidden shape == (batch_size, hidden size)\n",
    "        # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "        # we are doing this to perform addition to calculate the score\n",
    "        hidden_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "        # score shape == (batch_size, max_length, 1)\n",
    "        # we get 1 at the last axis because we are applying score to self.V\n",
    "        # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
    "        score = self.V(tf.nn.tanh(self.W1(values) + self.W2(hidden_with_time_axis)))\n",
    "\n",
    "        # attention_weights shape == (batch_size, max_length, 1)\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "        # context_vector shape after sum == (batch_size, hidden_size)\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights\n",
    "    \n",
    "attention_layer = BahdanauAttention(units)\n",
    "\n",
    "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
    "\n",
    "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
    "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder output shape: (batch_size, vocab size) (60, 1, 3)\n"
     ]
    }
   ],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, decoding_units, batch_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.decoding_units = decoding_units\n",
    "        #self.embedding = keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = keras.layers.GRU(self.decoding_units,\n",
    "                                    return_sequences=True,\n",
    "                                    return_state=True,\n",
    "                                    recurrent_initializer='glorot_uniform')\n",
    "        self.fc = keras.layers.Dense(vocab_size)\n",
    "        \n",
    "        self.fcn_4 = keras.layers.Dense(64, activation = 'relu')\n",
    "        self.fcn_5 = keras.layers.Dense(32, activation='relu')\n",
    "\n",
    "        # used for attention\n",
    "        self.attention = BahdanauAttention(self.decoding_units)\n",
    "\n",
    "    def call(self,  hidden, encoding_output,embedder):\n",
    "        # enc_output shape == (batch_size, max_length, hidden_size)\n",
    "        context_vector, attention_weights = self.attention(hidden, encoding_output)\n",
    "\n",
    "        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "        #x = self.embedding(x)\n",
    "\n",
    "        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), embedder], axis=-1)\n",
    "\n",
    "        # passing the concatenated vector to the GRU\n",
    "        output, state = self.gru(x)\n",
    "        x = self.fc(output)\n",
    "\n",
    "\n",
    "        return x, state, attention_weights\n",
    "    \n",
    "\n",
    "vocab_size=3\n",
    "decoder = Decoder( vocab_size ,embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "embeded = tf.expand_dims(embeded[:,0,:],1)\n",
    "sample_decoder_output, _, _ = decoder(sample_hidden, sample_output, embeded)\n",
    "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50full_seq2seq_Attenetion_200_60\n"
     ]
    }
   ],
   "source": [
    "optimizer = keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.MeanSquaredError( reduction=tf.keras.losses.Reduction.NONE)\n",
    "\n",
    "@tf.function\n",
    "def loss_function(real, pred):\n",
    "    \n",
    "    #mask = tf.math.logical_not(tf.math.equal(real, [0,0,0]))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    #mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    #loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)\n",
    "\n",
    "#checkpoint_dir = str(seq_len)+'test_seq2seq_Attenetion_'+str(units)+'_'+str(BATCH_SIZE)\n",
    "checkpoint_dir = str(seq_len)+'full_seq2seq_Attenetion_'+str(units)+'_'+str(BATCH_SIZE)\n",
    "\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.mkdir(checkpoint_dir)\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)\n",
    "\n",
    "\n",
    "print(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(inp, targ, encoding_hidden):\n",
    "    loss = 0\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        embeded_or, encoding_output, encoding_hidden = encoder(inp, encoding_hidden)\n",
    "\n",
    "        decoding_hidden = encoding_hidden\n",
    "        \n",
    "        embeded = tf.expand_dims(embeded_or[:,0,:],1)\n",
    "\n",
    "        #decoding_input = tf.expand_dims(inp[:,0,:], 1)\n",
    "\n",
    "        # Teacher forcing - feeding the target as the next input\n",
    "        for t in range(1, targ.shape[1]):\n",
    "            # passing enc_output to the decoder\n",
    "            predictions, decoding_hidden, _ = decoder( decoding_hidden, encoding_output, embeded)\n",
    "            tmp = np.expand_dims(targ[:,t,:],1)\n",
    "            loss += loss_function(tmp, predictions)\n",
    "\n",
    "            # using teacher forcing\n",
    "            embeded = tf.expand_dims(embeded_or[:,t,:],1)\n",
    "\n",
    "    batch_loss = (loss / int(targ.shape[1]))\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "    return batch_loss\n",
    "\n",
    "\n",
    "\n",
    "EPOCHS = 20\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    encoding_hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch, inp in enumerate(dataset.take(steps_per_epoch)):\n",
    "        batch_loss = train_step(inp, inp, encoding_hidden)\n",
    "        total_loss += batch_loss\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1, batch, batch_loss.numpy()))\n",
    "\n",
    "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "            \n",
    "    # saving (checkpoint) the model every 2 epochs\n",
    "    \n",
    "\n",
    "    print('Epoch {} Loss {:.4f}'.format(epoch + 1, total_loss / steps_per_epoch))\n",
    "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fa01f1b65b0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evaluate(inputs):\n",
    "    result = np.zeros((np.shape(inputs)))\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "  \n",
    "    inference_batch_size = inputs.shape[0]\n",
    "    hidden = [tf.zeros((inference_batch_size, units))]\n",
    "    embeded_or,encoding_out, encoding_hidden = encoder(inputs, hidden)\n",
    "\n",
    "    decoding_hidden = encoding_hidden\n",
    "\n",
    "\n",
    "\n",
    "    for t in range(seq_len):\n",
    "        embeded = tf.expand_dims(embeded_or[:,t,:],1)\n",
    "        predictions, decoding_hidden, attention_weights = decoder(decoding_hidden, encoding_out, embeded)\n",
    "\n",
    "    \n",
    "        result[:,t,:] = tf.squeeze(predictions)\n",
    "\n",
    "        # the predicted ID is fed back into the model\n",
    "        decoding_input = predictions\n",
    "\n",
    "    return result, inputs\n",
    "\n",
    "# function for plotting the attention weights\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "    fontdict = {'fontsize': 14}\n",
    "\n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "    plt.show()\n",
    "'''\n",
    "def make_pre(input):\n",
    "    result, sentence, attention_plot = evaluate(sentence)\n",
    "\n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "\n",
    "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))\n",
    "'''\n",
    "\n",
    "optimizer = keras.optimizers.Adam()\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    f = open(os.path.join(checkpoint_dir,'checkpoint'), 'w')\n",
    "    f.write('model_checkpoint_path: \"ckpt-'+str(i+1)+'\"\\n')\n",
    "    f.write('all_model_checkpoint_paths: \"ckpt-'+str(i+1)+'\"\\n')\n",
    "    f.close()\n",
    "    checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "    \n",
    "    result, _ = evaluate(data_valid)\n",
    "    mse_idv =loss_function(data_valid, result)\n",
    "    print(str(i+1)+': '+str(mse_idv.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = '156031_ex_cc-body_shore.ply'\n",
    "bundle = ply2np(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "def cal_mse(data_raw,data_pred):\n",
    "    mse = np.zeros(np.shape(data_raw)[0])\n",
    "    for i in range(np.shape(data_raw)[0]):\n",
    "        result = mean_squared_error(data_raw[i], data_pred[i])\n",
    "        mse[i] = result\n",
    "    return mse  \n",
    "mse_idv = cal_mse(test_data, result)\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(1)\n",
    "ax.hist(mse_idv, bins=200,range=(0,25), histtype='step')\n",
    "ax.set_xlabel('MSE')\n",
    "ax.set_ylabel('# streamlines') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
