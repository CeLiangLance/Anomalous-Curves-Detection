{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plyfile import PlyData\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from dipy.tracking.streamline import Streamlines\n",
    "from dipy.tracking.streamlinespeed import length\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlyStruct:\n",
    "    \"\"\"Class that process poly data\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.ply_data = None\n",
    "        self.idx = None\n",
    "        self.properties = None\n",
    "        self.stream_line = None\n",
    "\n",
    "    def load_poly_data(self, subpath: str, num_prop: int = None):\n",
    "        \"\"\"\n",
    "        Load ply file\n",
    "        :param str subpath: path of ply file\n",
    "        :param int num_prop: optional parmeter to only take the first num properties (e.g. only x,y,z coordinates)\n",
    "        \"\"\"\n",
    "        ply = PlyData.read(subpath)\n",
    "        property_list = [ply['vertices'].data[name] for name in ply['vertices'].data.dtype.names]\n",
    "        self.ply_data = np.array(property_list).T\n",
    "        if num_prop:\n",
    "            self.ply_data = self.ply_data[:, :num_prop]\n",
    "        self.idx = ply['fiber'].data['endindex']\n",
    "        self.properties = ply['vertices'].data.dtype.names\n",
    "        if num_prop:\n",
    "            self.properties = self.properties[:num_prop]\n",
    "   \n",
    "\n",
    "    def gen_stream_line(self):\n",
    "        self.stream_line = []\n",
    "        self.stream_line.append(self.ply_data[0:self.idx[0],:])\n",
    "        for i in range(len(self.idx)-1):\n",
    "            self.stream_line.append(self.ply_data[self.idx[i]:self.idx[i+1],:])\n",
    "\n",
    "            \n",
    "def zero_remove(darray):\n",
    "    \n",
    "    for i in range(np.shape(darray)[0]-1,-1,-1):\n",
    "        if not (np.around(darray[i], decimals=0) == 0 ).all():\n",
    "            return darray[0:i+1] \n",
    "            break           \n",
    "            \n",
    "def get_length(stream):\n",
    "    # to get the length of streamlines in this subject\n",
    "    len_table = []\n",
    "    for i in range(len(stream)):\n",
    "        len_table.append(np.shape(stream[i])[0])\n",
    "    return len_table\n",
    "\n",
    "def cal_mse(data_raw,data_pred):\n",
    "    mse = np.zeros(np.shape(data_raw)[0])\n",
    "    for i in range(np.shape(data_raw)[0]):\n",
    "        result = mean_squared_error(data_raw[i], data_pred[i])\n",
    "        mse[i] = result\n",
    "    return mse  \n",
    "\n",
    "\n",
    "def ply2np(name):\n",
    "    # convert a ply format to the matrix we are using\n",
    "    # input : '128127_ex_cc-body_shore.ply', name of a oly file\n",
    "    # optput: a matrix (#_of_fibers, #_of_vertex, 3 )\n",
    "    temo = PlyStruct()\n",
    "    temo.load_poly_data(os.path.join('data',name),num_prop=3)\n",
    "    #data = temo.ply_data\n",
    "  \n",
    "    temo.gen_stream_line()\n",
    "    stream = temo.stream_line\n",
    "\n",
    "    stream = np.array(stream)\n",
    "    len_table = get_length(stream)\n",
    "    subject = np.zeros((len(stream),np.max(len_table),3))\n",
    "    for i in range(len(stream)):\n",
    "        length = len_table[i]\n",
    "        subject[i,0:length,:] = stream[i]\n",
    "        \n",
    "    return subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index: 0       model: deep Bi GRU\n",
      "index: 1       model: deep Bi LSTM\n",
      "index: 2       model: deep GRU\n",
      "index: 3       model: deep LSTM\n",
      "index: 4       model: Bi GRU.h5\n",
      "index: 5       model: Undercomplete GRU\n",
      "index: 6       model: Autoencoder GRU\n",
      "index: 7       model: Bidirectional LSTM\n",
      "index: 8       model: Undercomplete LSTM\n",
      "index: 9       model: Autoencoder LSTM\n",
      "index: 10       model: Autoencoder RNN\n",
      "index: 11       model: Bidirectional RNN\n",
      "index: 12       model: Undercomplete RNN\n"
     ]
    }
   ],
   "source": [
    "model_list = ['deep_bi_GRU.h5', 'deep_bi_LSTM.h5', 'deep_GRU.h5', 'deep_LSTM.h5', \n",
    "              'GRU_bi_model.h5', 'GRU_dr_model.h5', 'GRU_model.h5', 'LSTM_bi_model.h5', \n",
    "              'LSTM_dr_model.h5', 'LSTM_model.h5', 'simple_rnn_2_model.h5', \n",
    "              'sRNN_bi_model.h5', 'toy_rnn_2_dr_model.h5']\n",
    "\n",
    "titles = ['deep Bi GRU', 'deep Bi LSTM', 'deep GRU', 'deep LSTM', \n",
    "          'Bi GRU.h5', 'Undercomplete GRU', 'Autoencoder GRU', 'Bidirectional LSTM', \n",
    "          'Undercomplete LSTM', 'Autoencoder LSTM', 'Autoencoder RNN', \n",
    "          'Bidirectional RNN', 'Undercomplete RNN']\n",
    "\n",
    "for i in range(len(titles)):\n",
    "    print('index: {}       model: {}'.format(i,titles[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# file name, control parameter ↓"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = '156031_ex_cc-body_shore.ply'\n",
    "thre_con = 85\n",
    "len_thre = 40\n",
    "model_index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bundle = ply2np(name)\n",
    "\n",
    "# load DL model\n",
    "\n",
    "model_path = os.path.join('trained_models',model_list[model_index])\n",
    "model = tf.keras.models.load_model(model_path,custom_objects={'leaky_relu': tf.nn.leaky_relu})\n",
    "\n",
    "# make reconstruction \n",
    "denoise = model(bundle)\n",
    "denoise = denoise.numpy()\n",
    "# calculate MSE\n",
    "mse_idv = cal_mse(bundle, denoise)\n",
    "\n",
    "\n",
    "# detection results by threshold the MSE\n",
    "thre = np.percentile(mse_idv,thre_con)\n",
    "\n",
    "pred_1 = 1*(mse_idv<thre)\n",
    "bundle_str = Streamlines()\n",
    "\n",
    "for i in range(np.shape(bundle)[0]):\n",
    "    tmp = bundle[i]\n",
    "    tmp = zero_remove(tmp)\n",
    "    #tmp = tmp[~np.all(tmp == 0, axis=-1)]\n",
    "    #tmp = np.around(tmp, decimals=0)\n",
    "    bundle_str.append(tmp)\n",
    "    \n",
    "lengths = length(bundle_str)\n",
    "\n",
    "pred_2 = 1*(lengths > len_thre)\n",
    "\n",
    "pred = 1*((pred_1 + pred_2)>1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ↓\n",
    "a binary visualization of the detection \n",
    "\n",
    "red: normal curves\n",
    "\n",
    "white : anomalous curves "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r'toolkit')\n",
    "from visualize_score import  visualize_streamline, visualize_streamline_removed\n",
    "visualize_streamline(bundle,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ↓\n",
    "a visualization of the anomalous fibers removal  \n",
    "\n",
    "the  color is the default color by position "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from dipy.tracking.streamline import Streamlines,cluster_confidence\n",
    "from dipy.tracking.distances import bundles_distances_mdf\n",
    "from dipy.tracking.streamlinespeed import (compress_streamlines, length,\n",
    "                                           set_number_of_points)\n",
    "\n",
    "\n",
    "data_new = np.delete(bundle, np.where(pred == 0), axis=0)\n",
    "\n",
    "\n",
    "def zero_remove(darray):\n",
    "    \n",
    "    for i in range(np.shape(darray)[0]-1,-1,-1):\n",
    "        if not (np.around(darray[i], decimals=0) == 0 ).all():\n",
    "            return darray[0:i+1] \n",
    "            break\n",
    "\n",
    "from dipy.viz import colormap\n",
    "from dipy.viz import actor, window\n",
    "\n",
    "subsamp_sls = Streamlines()\n",
    "\n",
    "for i in range(np.shape(data_new)[0]):\n",
    "    tmp = data_new[i]\n",
    "    tmp = zero_remove(tmp)\n",
    "    #tmp = tmp[~np.all(tmp == 0, axis=-1)]\n",
    "    #tmp = np.around(tmp, decimals=0)\n",
    "    subsamp_sls.append(tmp)\n",
    "    \n",
    "color = colormap.line_colors(subsamp_sls)\n",
    "\n",
    "streamlines_actor = actor.line(subsamp_sls,\n",
    "                               colormap.line_colors(subsamp_sls))\n",
    "\n",
    "# Create the 3D display.\n",
    "scene = window.Scene()\n",
    "scene.add(streamlines_actor)\n",
    "\n",
    "window.show(scene)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
