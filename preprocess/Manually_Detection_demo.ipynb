{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from plyfile import PlyData\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "from dipy.tracking.streamline import Streamlines, cluster_confidence\n",
    "\n",
    "from dipy.tracking.distances import bundles_distances_mdf\n",
    "from dipy.tracking.streamlinespeed import (compress_streamlines, length,\n",
    "                                           set_number_of_points)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import preprocessing\n",
    "\n",
    "class PlyStruct:\n",
    "    \"\"\"Class that process poly data\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.ply_data = None\n",
    "        self.idx = None\n",
    "        self.properties = None\n",
    "        self.stream_line = None\n",
    "\n",
    "    def load_poly_data(self, subpath: str, num_prop: int = None):\n",
    "        \"\"\"\n",
    "        Load ply file\n",
    "        :param str subpath: path of ply file\n",
    "        :param int num_prop: optional parmeter to only take the first num properties (e.g. only x,y,z coordinates)\n",
    "        \"\"\"\n",
    "        ply = PlyData.read(subpath)\n",
    "        property_list = [ply['vertices'].data[name] for name in ply['vertices'].data.dtype.names]\n",
    "        self.ply_data = np.array(property_list).T\n",
    "        if num_prop:\n",
    "            self.ply_data = self.ply_data[:, :num_prop]\n",
    "        self.idx = ply['fiber'].data['endindex']\n",
    "        self.properties = ply['vertices'].data.dtype.names\n",
    "        if num_prop:\n",
    "            self.properties = self.properties[:num_prop]\n",
    "   \n",
    "    def gen_stream_line(self):\n",
    "        self.stream_line = []\n",
    "        self.stream_line.append(self.ply_data[0:self.idx[0],:])\n",
    "        for i in range(len(self.idx)-1):\n",
    "            self.stream_line.append(self.ply_data[self.idx[i]:self.idx[i+1],:])\n",
    "\n",
    "\n",
    "\n",
    "def zero_remove(darray):\n",
    "    \n",
    "    for i in range(np.shape(darray)[0]-1,-1,-1):\n",
    "        if not (np.around(darray[i], decimals=0) == 0 ).all():\n",
    "            return darray[0:i+1] \n",
    "            break\n",
    "\n",
    "def get_length(stream):\n",
    "    # to get the length of streams in this subject\n",
    "    len_table = []\n",
    "    for i in range(len(stream)):\n",
    "        len_table.append(np.shape(stream[i])[0])\n",
    "    return len_table\n",
    "\n",
    "def cal_mse(data_raw,data_pred):\n",
    "    mse = np.zeros(np.shape(data_raw)[0])\n",
    "    for i in range(np.shape(data_raw)[0]):\n",
    "        result = mean_squared_error(data_raw[i], data_pred[i])\n",
    "        mse[i] = result\n",
    "    return mse  \n",
    "\n",
    "\n",
    "def ply2np(name):\n",
    "    # convert a ply format to the matrix we are using\n",
    "    # input : '128127_ex_cc-body_shore.ply', name of a oly file\n",
    "    # optput: a matrix (#_of_fibers, #_of_vertex, 3 )\n",
    "    temo = PlyStruct()\n",
    "    temo.load_poly_data(os.path.join('..','data',name),num_prop=3)\n",
    "    #data = temo.ply_data\n",
    "  \n",
    "    temo.gen_stream_line()\n",
    "    stream = temo.stream_line\n",
    "\n",
    "\n",
    "    stream = np.array(stream)\n",
    "    len_table = get_length(stream)\n",
    "    subject = np.zeros((len(stream),np.max(len_table),3))\n",
    "    for i in range(len(stream)):\n",
    "        lengt = len_table[i]\n",
    "        subject[i,0:lengt,:] = stream[i]\n",
    "        \n",
    "    return subject"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# file name, control parameter ↓"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = '156031_ex_cc-body_shore.ply'\n",
    "IF_thre = 0.17\n",
    "cci_thre = 2\n",
    "dis_thre = 630\n",
    "len_con = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bundle = ply2np(name)\n",
    "\n",
    "def cal_cov_sub(fiber_sub):\n",
    "    \n",
    "\n",
    "    streamlines_evl = Streamlines()\n",
    "    \n",
    "    for i in range(np.shape(fiber_sub)[0]):\n",
    "        tmp = fiber_sub[i]\n",
    "        tmp = zero_remove(tmp)\n",
    "        streamlines_evl.append(tmp)\n",
    "        \n",
    "\n",
    "    \n",
    "    #==============\n",
    "    fiber_one = fiber_sub[0].transpose()\n",
    "    fiber_one_std = preprocessing.scale(fiber_one)\n",
    "    \n",
    "    covarience = np.cov(fiber_one_std)\n",
    "    result = np.array( [covarience[0,0], covarience[1,1], covarience[2,2],covarience[0,1], covarience[0,2],covarience[1,2]]).transpose()\n",
    "    \n",
    "    for i in range(1,np.shape(fiber_sub)[0]):\n",
    "            fiber_one = fiber_sub[i].transpose()\n",
    "            fiber_one_std = preprocessing.scale(fiber_one)\n",
    "            \n",
    "            covarience = np.cov(fiber_one_std)\n",
    "            #tmp = np.array( [covarience[0,0], covarience[1,1], covarience[2,2]]).transpose()\n",
    "            tmp = np.array( [covarience[0,0], covarience[1,1], covarience[2,2],covarience[0,1], covarience[0,2],covarience[1,2]]).transpose()\n",
    "            result = np.vstack((result,tmp))\n",
    "    return result\n",
    "\n",
    "\n",
    "result_if = cal_cov_sub(bundle)\n",
    "result_if = cal_cov_sub(bundle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\_iforest.py:248: FutureWarning: 'behaviour' is deprecated in 0.22 and will be removed in 0.24. You should not pass or set this parameter.\n",
      "  FutureWarning\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "clf = IsolationForest( behaviour = \"new\", max_samples=200, random_state = 1, contamination=IF_thre )\n",
    "pred_if = clf.fit_predict(result_if)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the distance score map\n",
    "avg_dist = np.load(os.path.join('..','toolkit','avg_dist.npy'))\n",
    "\n",
    "ref_affine = np.array([[  -1.25,    0.  ,    0.  ,   90.  ],\n",
    "                       [   0.  ,    1.25,    0.  , -126.  ],\n",
    "                       [   0.  ,    0.  ,    1.25,  -72.  ],\n",
    "                       [   0.  ,    0.  ,    0.  ,    1.  ]])\n",
    "\n",
    "# calculate distancr score each voxel\n",
    "def cal_dist_score(dist_array,position_array):\n",
    "    # per fiber\n",
    "    result = 0\n",
    "    for i in range(np.shape(position_array)[0]):\n",
    "        x,y,z = position_array[i]\n",
    "        tmp = dist_array[x,y,z]\n",
    "        result += tmp\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "def cal_score_subject(subject_array):\n",
    "    #per subject\n",
    "    scores = []\n",
    "    for i in range(np.shape(subject_array)[0]):\n",
    "    \n",
    "        aa = subject_array[i]\n",
    "        aa2 = zero_remove(aa)\n",
    "        aa3 = aa2.T \n",
    "        \n",
    "        bb = np.ones((4,np.shape(aa3)[1]))\n",
    "        bb[0:3,:]=aa3\n",
    "        cc = np.dot( np.linalg.inv(ref_affine),bb)\n",
    "        \n",
    "        cc_int = cc[0:3,:].T.astype(np.int16)\n",
    "        cc_uniques = np.unique(cc_int,axis=0)\n",
    "        \n",
    "        score_tmp = cal_dist_score(avg_dist,cc_uniques)\n",
    "        scores.append(score_tmp)\n",
    "        \n",
    "    return np.array(scores)\n",
    "\n",
    "result_dis = cal_score_subject(bundle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the CCI score\n",
    "streamlines_evl = Streamlines()\n",
    "for j in range(np.shape(bundle)[0]):\n",
    "    tmp = bundle[j]\n",
    "    tmp = zero_remove(tmp)\n",
    "    streamlines_evl.append(tmp)\n",
    "\n",
    "result_cci = cluster_confidence(streamlines_evl,subsample=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "preds_cci = 1*(result_cci>cci_thre)\n",
    "preds_dis  = 1*(result_dis<dis_thre)\n",
    "pred_if = 1*(pred_if>0)\n",
    "# combine three methods\n",
    "pred_1 = 1*((preds_cci + preds_dis +pred_if)>2)\n",
    "\n",
    "# control by length \n",
    "bundle_str = Streamlines()\n",
    "\n",
    "for i in range(np.shape(bundle)[0]):\n",
    "    tmp = bundle[i]\n",
    "    tmp = zero_remove(tmp)\n",
    "\n",
    "    bundle_str.append(tmp)\n",
    "    \n",
    "lengths = length(bundle_str)\n",
    "len_thre = len_con\n",
    "pred_2 = 1*(lengths > len_thre)\n",
    "\n",
    "pred = 1*((pred_1 + pred_2)>1)\n",
    "\n",
    "save_path = 'Detection'+name.split('_')[0]+'_manual'\n",
    "np.save(save_path,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ↓\n",
    "a binary visualization of the detection \n",
    "\n",
    "red: normal curves\n",
    "\n",
    "white : anomalous curves "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r'../toolkit')\n",
    "from visualize_score import  visualize_streamline, visualize_streamline_removed\n",
    "visualize_streamline(bundle,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
